{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc0692a",
   "metadata": {},
   "source": [
    "# QuantCell Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score, f1_score, precision_score, balanced_accuracy_score\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "os.chdir('/home/LULAB/wboohar/CODEX/data_processing/code')\n",
    "from codex_project import codex_project, read_marker_combos\n",
    "from quantcell import quantcell_project\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = '/store/Projects/wboohar/PhenoCycler/annotation_strategies/marker_combos_062525_updated_verified.json'   \n",
    "base_dir = '/store/Projects/wboohar/PhenoCycler' \n",
    "project_name = 'QuantCellPaper'\n",
    "project_path = f'{base_dir}/{project_name}'\n",
    "data_path = f'{base_dir}/raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f43687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cell_order = [\n",
    "    'KLS',\n",
    "    'MEP',\n",
    "    'CMP',\n",
    "    'GMP',\n",
    "    'CLP',\n",
    "    'CFU-E',\n",
    "    'MkP',\n",
    "    'Erythroblasts',\n",
    "    'Erythrocytes',\n",
    "    'Megakaryocytes',\n",
    "    'B Cells',\n",
    "    'CD4 T Cells',\n",
    "    'CD8 T Cells',\n",
    "    'cDC',\n",
    "    'Double Negative T Cells',\n",
    "    'Monocytes',\n",
    "    'Neutrophils',\n",
    "    'Arterial ECs',\n",
    "    'Capillary ECs',\n",
    "    'Other BM ECs',\n",
    "    'Lepr+ Perivascular Cells']\n",
    "\n",
    "\n",
    "color_order = {\n",
    "    'KLS' : 'yellowgreen',\n",
    "    'MEP' : 'palegreen',\n",
    "    'CMP' : 'orange',\n",
    "    'GMP' : 'olive',\n",
    "    'CLP' : 'darkorange',\n",
    "    'CFU-E' : 'green',\n",
    "    'MkP' : 'darkseagreen',\n",
    "    'Erythroblasts' : 'gold',\n",
    "    'Erythrocytes' : 'wheat',\n",
    "    'Megakaryocytes' : 'cornflowerblue',\n",
    "    'B Cells' : 'violet',\n",
    "    'CD4 T Cells' : 'red',\n",
    "    'CD8 T Cells' : 'orangered',\n",
    "    'cDC' : 'chocolate',\n",
    "    'Double Negative T Cells' : 'blue',\n",
    "    'Monocytes' : 'chartreuse',\n",
    "    'Neutrophils' : 'teal',\n",
    "    'Arterial ECs' : 'rosybrown',\n",
    "    'Capillary ECs' : 'brown',\n",
    "    'Other BM ECs' : 'orange',\n",
    "    'Lepr+ Perivascular Cells' : 'deepskyblue',\n",
    "    'Other' : 'white'\n",
    "}\n",
    "\n",
    "if os.path.exists(f'{project_path}/label_encoder.joblib'):\n",
    "    encoder = joblib.load(f'{project_path}/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, name,  normalization='row', **kwargs):\n",
    "    if normalization == 'row':\n",
    "        row_sums = conf_matrix.sum(axis=1) # row sums\n",
    "        conf_matrix = conf_matrix.divide(row_sums, axis=0) # normalize by row sums\n",
    "    elif normalization == 'col':\n",
    "        col_sums = conf_matrix.sum(axis=0) # col sums\n",
    "        conf_matrix = conf_matrix.divide(col_sums, axis=1) # normalize by col sums\n",
    "    elif normalization == 'all':\n",
    "        total_sum = conf_matrix.sum().sum()\n",
    "        conf_matrix = conf_matrix / total_sum\n",
    "\n",
    "    ax=sns.heatmap(conf_matrix, \n",
    "                linecolor='grey', \n",
    "                linewidth=0.01, \n",
    "                xticklabels=cell_order, \n",
    "                yticklabels=cell_order,\n",
    "                cmap=sns.color_palette(\"flare\", as_cmap=True),\n",
    "                cbar_kws={'format' :  FuncFormatter(lambda x, _: f'{x:.0f}%'), 'boundaries': np.linspace(0, 1, 100)},\n",
    "                **kwargs)\n",
    "    ax.collections[0].colorbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.collections[0].colorbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "    ax.tick_params(length=6)\n",
    "    ax.set_xticklabels(cell_order, rotation=90)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6575d8",
   "metadata": {},
   "source": [
    "### Fig 1\n",
    "Voronoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_codex = pd.read_csv(f'{project_path}/codex_conventional_QuantCellPaper.csv', index_col=0)\n",
    "relabeled_codex = pd.read_csv(f'{project_path}/codex_quantcell_QuantCellPaper.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LIM = (9150, 9257)\n",
    "Y_LIM = (947, 878)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fd6b1",
   "metadata": {},
   "source": [
    "Marker Expression Annotation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "codex = original_codex\n",
    "\n",
    "marker='CD45'\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "section_mask = (codex['x'] > X_LIM[0] - 50) & (codex['x'] < X_LIM[1] + 50) & (codex['y'] > Y_LIM[1] - 50) & (codex['y'] < Y_LIM[0] + 50)\n",
    "section = codex.loc[section_mask, :].copy()\n",
    "section.reset_index(inplace=True, drop=True)\n",
    "vor = Voronoi(section.loc[:, ['x', 'y']])\n",
    "fig = voronoi_plot_2d(vor, show_vertices=False, show_points=False, line_width=0.05, ax=ax)\n",
    "axs = fig.axes\n",
    "\n",
    "section.loc[:, 'color'] = section.loc[:, marker].apply(lambda x: 'grey' if x.count('+') else 'white')\n",
    "\n",
    "for r in range(len(vor.point_region)):\n",
    "    region = vor.regions[vor.point_region[r]]\n",
    "    if not -1 in region:\n",
    "        polygon = [vor.vertices[i] for i in region]\n",
    "        plt.fill(*zip(*polygon), color = section.loc[r, 'color'], edgecolor='black')\n",
    "\n",
    "plt.xlim(X_LIM)\n",
    "plt.ylim(Y_LIM)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{project_path}/section_voronoi_{marker}_expression.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5cd70",
   "metadata": {},
   "source": [
    "Conventional Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "codex = original_codex\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "section_mask = (codex['x'] > X_LIM[0] - 50) & (codex['x'] < X_LIM[1] + 50) & (codex['y'] > Y_LIM[1] - 50) & (codex['y'] < Y_LIM[0] + 50)\n",
    "section = codex.loc[section_mask, :].copy()\n",
    "section.reset_index(inplace=True, drop=True)\n",
    "vor = Voronoi(section.loc[:, ['x', 'y']])\n",
    "fig = voronoi_plot_2d(vor, show_vertices=False, show_points=False, line_width=0.05, ax=ax)\n",
    "axs = fig.axes\n",
    "\n",
    "\n",
    "for r in range(len(vor.point_region)):\n",
    "    region = vor.regions[vor.point_region[r]]\n",
    "    if not -1 in region:\n",
    "        polygon = [vor.vertices[i] for i in region]\n",
    "        plt.fill(*zip(*polygon), color = color_order[section.loc[r, 'cell_type']], edgecolor='black')\n",
    "\n",
    "plt.xlim(X_LIM)\n",
    "plt.ylim(Y_LIM)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{project_path}/section_voronoi_original.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1538e33",
   "metadata": {},
   "source": [
    "QuantCell Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "codex = relabeled_codex\n",
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "section_mask = (codex['x'] > X_LIM[0] - 50) & (codex['x'] < X_LIM[1] + 50) & (codex['y'] > Y_LIM[1] - 50) & (codex['y'] < Y_LIM[0] + 50)\n",
    "section = codex.loc[section_mask, :].copy()\n",
    "section.reset_index(inplace=True, drop=True)\n",
    "vor = Voronoi(section.loc[:, ['x', 'y']])\n",
    "fig = voronoi_plot_2d(vor, show_vertices=False, show_points=False, line_width=0.05, ax=ax)\n",
    "axs = fig.axes\n",
    "\n",
    "\n",
    "for r in range(len(vor.point_region)):\n",
    "    region = vor.regions[vor.point_region[r]]\n",
    "    if not -1 in region:\n",
    "        polygon = [vor.vertices[i] for i in region]\n",
    "        plt.fill(*zip(*polygon), color = color_order[section.loc[r, 'cell_type']], edgecolor='black')\n",
    "\n",
    "plt.xlim(X_LIM)\n",
    "plt.ylim(Y_LIM)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{project_path}/section_voronoi_relabeled.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1b989",
   "metadata": {},
   "source": [
    "### Fig 2\n",
    "\n",
    "\n",
    "A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf_performance_dict=joblib.load(f'{project_path}/base_models/base_clf_performance_dict.joblib')\n",
    "base_classifier_names=['Nearest Neighbors', 'Multilayer Perceptron', 'Random Forest', 'Extra Trees', 'Decision Tree', 'Gaussian Naive-Bayes', 'Ridge Classifier', 'Linear SVC']\n",
    "\n",
    "macro_pr_rec = np.zeros((len(base_classifier_names), 1000, 2, 10))\n",
    "\n",
    "for n, lab in enumerate(base_classifier_names):\n",
    "\n",
    "    for fold in range(10):\n",
    "\n",
    "        macro_pr_rec[n, :, 0, fold]=base_clf_performance_dict[lab][2][fold][0]\n",
    "        macro_pr_rec[n, :, 1, fold]=base_clf_performance_dict[lab][2][fold][1]\n",
    "\n",
    "num_classes = base_clf_performance_dict[base_classifier_names[0]][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed4f27",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad963d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_AP_list = [np.mean([base_clf_performance_dict[lab][0][fold] for fold in range(10)]) for lab in base_classifier_names]\n",
    "\n",
    "lab_order = np.argsort(macro_AP_list)\n",
    "macro_AP_list = [macro_AP_list[n] for n in lab_order]\n",
    "names_sorted = [base_classifier_names[n] for n in lab_order]\n",
    "\n",
    "min_macro = 1/num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7328e",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = joblib.load(f'{project_path}/model_selection/top3models_results.joblib')\n",
    "\n",
    "order = ['RandomForestClassifier', 'MLPClassifier', 'ExtraTreesClassifier']\n",
    "\n",
    "standard_aps={}\n",
    "optimized_aps={}\n",
    "\n",
    "for clf_name in results.keys():\n",
    "    acc = 0\n",
    "    score = 0\n",
    "    y_test_list, y_pred_list, y_proba_list = results[clf_name]\n",
    "    for n in range(10):\n",
    "        score += average_precision_score(y_test_list[n], y_proba_list[n], average='macro')\n",
    "        acc += balanced_accuracy_score(y_test_list[n], y_pred_list[n])\n",
    "\n",
    "    acc /= 10\n",
    "    score /= 10\n",
    "    print(f'{clf_name} Macro-averaged AUPRC: {score:.3}')\n",
    "    print(f'{clf_name} Balanced Accuracy: {acc:.3}')\n",
    "    if 'untuned' in clf_name:\n",
    "        clf_name = clf_name.split('_untuned')[0]\n",
    "        standard_aps[clf_name] = score\n",
    "    else:\n",
    "        clf_name = clf_name.split('_tuned')[0]\n",
    "        optimized_aps[clf_name] = score\n",
    "\n",
    "\n",
    "standard_aps = [standard_aps[name] for name in order]\n",
    "optimized_aps = [optimized_aps[name] for name in order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_loc_dict = joblib.load(f'{project_path}/model_selection/stats_loc_dict_included.joblib')\n",
    "    \n",
    "\n",
    "location_order = ['Membrane', 'Cytoplasm', 'Nucleus', 'Cell', 'All']\n",
    "stat_order = ['Min', 'Max', 'Std.Dev.', 'Median', 'Mean', 'All']\n",
    "\n",
    "included_average_precision_dict={}\n",
    "included_average_precision_std_dict={}\n",
    "\n",
    "\n",
    "for location in location_order:\n",
    "    included_average_precision_dict[location] = {}\n",
    "    included_average_precision_std_dict[location] = {}\n",
    "    for stat in stat_order:\n",
    "\n",
    "        y_true_dict = stats_loc_dict[location][stat][0]\n",
    "        y_proba_dict = stats_loc_dict[location][stat][2]\n",
    "\n",
    "        average_precision_list = []\n",
    "        for n in y_true_dict.keys():\n",
    "            average_precision_list.append(average_precision_score(y_true_dict[n], y_proba_dict[n], average='macro'))\n",
    "        included_average_precision_dict[location][stat] = np.mean(average_precision_list)\n",
    "        included_average_precision_std_dict[location][stat] = np.std(average_precision_list)\n",
    "\n",
    "included_df=pd.DataFrame(included_average_precision_dict).T\n",
    "included_std_df=pd.DataFrame(included_average_precision_std_dict).T\n",
    "\n",
    "included_text_df=included_df.copy()\n",
    "\n",
    "for row in included_text_df.index:\n",
    "    for col in included_text_df.columns:\n",
    "            included_text_df.loc[row, col] = f'{included_text_df.loc[row, col]:.3f}\\n±{included_std_df.loc[row, col]:.3f}'\n",
    "\n",
    "baseline = included_df.loc['All', 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_dict = joblib.load(f'{project_path}/model_selection/stats_loc_dict_excluded.joblib')\n",
    "\n",
    "excluded_average_precision_dict={}\n",
    "excluded_average_precision_std_dict={}\n",
    "\n",
    "\n",
    "for location in location_order:\n",
    "    excluded_average_precision_dict[location] = {}\n",
    "    excluded_average_precision_std_dict[location] = {}\n",
    "    for stat in stat_order:\n",
    "\n",
    "        y_true_dict = leave_one_out_dict[location][stat][0]\n",
    "        y_proba_dict = leave_one_out_dict[location][stat][2]\n",
    "\n",
    "        average_precision_list = []\n",
    "        if location == 'All' and stat == 'All':\n",
    "            excluded_average_precision_dict[location][stat] = None\n",
    "            excluded_average_precision_std_dict[location][stat] = None\n",
    "            continue\n",
    "\n",
    "        for n in y_true_dict.keys():\n",
    "            average_precision_list.append(average_precision_score(y_true_dict[n], y_proba_dict[n], average='macro'))\n",
    "        excluded_average_precision_dict[location][stat] = np.mean(average_precision_list)\n",
    "        excluded_average_precision_std_dict[location][stat] = np.std(average_precision_list)\n",
    "    \n",
    "excluded_df=baseline - pd.DataFrame(excluded_average_precision_dict).T\n",
    "excluded_std_df=pd.DataFrame(included_average_precision_std_dict).T\n",
    "\n",
    "excluded_text_df=excluded_df.copy()\n",
    "\n",
    "for row in excluded_text_df.index:\n",
    "    for col in excluded_text_df.columns:\n",
    "            excluded_text_df.loc[row, col] = f'{excluded_text_df.loc[row, col]:.3f}\\n±{excluded_std_df.loc[row, col]:.3f}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39ffd8",
   "metadata": {},
   "source": [
    "Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fontsize=24\n",
    "small_fontsize=21\n",
    "big_fontsize=30\n",
    "plt.rcParams['font.size'] = default_fontsize\n",
    "\n",
    "color_dict = {\n",
    "    'Nearest Neighbors': '#1f77b4',\n",
    "    'Multilayer Perceptron': 'mediumslateblue',\n",
    "    'Random Forest': '#2ca02c',\n",
    "    'Extra Trees': '#d62728',\n",
    "    'Decision Tree': 'darkgoldenrod',\n",
    "    'Gaussian Naive-Bayes': '#8c564b',\n",
    "    'Ridge Classifier': 'darkcyan',\n",
    "    \"Linear SVC\": '#e377c2'\n",
    "}\n",
    "\n",
    "\n",
    "optimized_classifier_names = ['Random\\nforest', 'Multilayer\\nperceptron', 'Extra trees']\n",
    "\n",
    "max_val=np.nanmax(excluded_df.values)\n",
    "min_val=np.nanmin(excluded_df.values)\n",
    "\n",
    "high_rgb=(1, 0, 0)\n",
    "low_rgb=(0, 0, 1)\n",
    "\n",
    "strength=0.5\n",
    "pivot=int(np.abs(min_val)/np.abs(max_val-min_val)*256)\n",
    "\n",
    "colors=np.zeros((256, 3))\n",
    "\n",
    "\n",
    "colors[:pivot, 0] = 1\n",
    "colors[pivot:, 0] = np.linspace(1, 1-strength, 256-pivot)\n",
    "colors[:pivot, 1] = np.linspace(1-strength, 1, pivot)\n",
    "colors[pivot:, 1] = np.linspace(1, 1-strength, 256-pivot)\n",
    "colors[:pivot, 2] = np.linspace(1-strength, 1, pivot)\n",
    "colors[pivot:, 2] = 1\n",
    "\n",
    "\n",
    "custom_coolwarm_cmap = LinearSegmentedColormap.from_list('Custom_Coolwarm', colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a662495",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17, 22))\n",
    "axd={}\n",
    "axd['A'] = fig.add_subplot(3, 3, 1)\n",
    "axd['B'] = fig.add_subplot(3, 3, 2)\n",
    "axd['C'] = fig.add_subplot(3, 3, 4)\n",
    "axd['D'] = fig.add_subplot(3, 3, 5)\n",
    "axd['X'] = fig.add_subplot(3, 3, 6)\n",
    "axd['E'] = fig.add_subplot(3, 3, 7)\n",
    "axd['Y'] = fig.add_subplot(3, 3, 8)\n",
    "\n",
    "\n",
    "axd['A'].set_position([0.05, 0.75, 0.3, 0.23])\n",
    "axd['B'].set_position([0.6, 0.75, 0.32, 0.23])\n",
    "\n",
    "axd['C'].set_position([0.05, 0.4, 0.37, 0.285])\n",
    "axd['D'].set_position([0.52, 0.4, 0.4, 0.285])\n",
    "axd['X'].set_position([0.94, 0.4, 0.02, 0.285])\n",
    "\n",
    "axd['E'].set_position([0.05, 0.05, 0.4, 0.285])\n",
    "axd['Y'].set_position([0.47, 0.05, 0.02, 0.285])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n, lab in enumerate(base_classifier_names):\n",
    "    axd['A'].plot(np.mean(macro_pr_rec[n, :, 1, :], axis=1), np.mean(macro_pr_rec[n, :, 0, :], axis=1), color=color_dict[lab], label=lab, linewidth=4, alpha=0.6)\n",
    "\n",
    "axd['A'].set_xlim(0, 1)\n",
    "axd['A'].spines[['top', 'right']].set_visible(False)\n",
    "axd['A'].set_ylim(0.45, 1)\n",
    "axd['A'].axvline(1, linestyle='--', color='black', linewidth=3)\n",
    "\n",
    "\n",
    "axd['A'].set_xlabel('Recall', fontsize=default_fontsize)\n",
    "axd['A'].set_ylabel('Precision', fontsize=default_fontsize)\n",
    "axd['A'].tick_params(axis='both', which='major', labelsize=default_fontsize)\n",
    "\n",
    "print('Minimum macro-averaged AUPRC:', min_macro)\n",
    "\n",
    "\n",
    "\n",
    "axd['B'].barh(names_sorted, macro_AP_list, color='white', alpha=1, edgecolor='black')\n",
    "axd['B'].barh(names_sorted, macro_AP_list, color=[color_dict[base_classifier_names[n]] for n in lab_order], alpha=0.6, edgecolor='black')\n",
    "\n",
    "axd['B'].set_yticklabels(names_sorted)\n",
    "\n",
    "axd['B'].axvline(min_macro, color='black', linestyle='--', linewidth=1.5)\n",
    "\n",
    "axd['B'].spines[['top', 'right']].set_visible(False)\n",
    "axd['B'].set_xlim(0, 1)\n",
    "\n",
    "def sentence_case(label_list):\n",
    "    word_list = [word.get_text().lower() for word in label_list]\n",
    "    word_list = [x[0].upper() + x[1:] for x in word_list]\n",
    "    if 'Linear svc' in word_list:\n",
    "        word_list[word_list.index('Linear svc')] = 'Linear SVC'\n",
    "    return word_list\n",
    "\n",
    "axd['B'].set_xlabel('Average precision', fontsize=default_fontsize)\n",
    "axd['B'].tick_params(axis='both', which='major', labelsize=default_fontsize)\n",
    "axd['B'].set_yticklabels(sentence_case(axd['B'].get_yticklabels()), fontsize=default_fontsize)\n",
    "\n",
    "axd['C'].bar([0.75, 2.75, 4.75], standard_aps, width=0.75, color='white',zorder=1, alpha=1, edgecolor='black')\n",
    "axd['C'].bar([0.75, 2.75, 4.75], standard_aps, width=0.75, color=['#2ca02c', 'mediumslateblue', '#d62728'],zorder=2, alpha=0.6, edgecolor='black')\n",
    "\n",
    "axd['C'].bar([1.5, 3.5, 5.5], optimized_aps,width=0.75, color='white',zorder=1, alpha=1, hatch='\\\\\\\\',edgecolor='black')\n",
    "axd['C'].bar([1.5, 3.5, 5.5], optimized_aps,width=0.75, color=['#2ca02c', 'mediumslateblue', '#d62728'],zorder=2, alpha=1, edgecolor='black')\n",
    "axd['C'].set_ylim([0.80, 1])\n",
    "\n",
    "axd['C'].set_ylabel('Average precision', fontsize=default_fontsize)\n",
    "axd['C'].spines[['right', 'top']].set_visible(False)\n",
    "axd['C'].tick_params(axis='both', which='major', labelsize=default_fontsize)\n",
    "\n",
    "circ1 = mpatches.Patch( facecolor='white',alpha=1,label='Default', edgecolor='black')\n",
    "circ2= mpatches.Patch( facecolor='gray',alpha=1, label='Hyperparameter tuned', edgecolor='black')\n",
    "axd['C'].set_xticks([1.125, 3.125, 5.125], optimized_classifier_names, fontsize=default_fontsize)\n",
    "axd['C'].set_yticks([0.85, 0.9, 0.95, 1])\n",
    "axd['C'].set_ylim([0.85, 1])\n",
    "axd['C'].legend(handles=[circ1, circ2], fontsize=default_fontsize, edgecolor='white', bbox_to_anchor=[0.9, 1.05])\n",
    "\n",
    "sns.heatmap(included_df.loc[location_order, stat_order], \n",
    "            annot=included_text_df.loc[location_order, stat_order], \n",
    "            fmt='',\n",
    "            vmin=0,\n",
    "            vmax=1, \n",
    "            cmap='Reds',\n",
    "            annot_kws={\"size\": small_fontsize},\n",
    "            ax=axd['D'],\n",
    "            cbar_ax=axd['X'])\n",
    "\n",
    "axd['D'].tick_params(labelsize=default_fontsize)\n",
    "axd['D'].set_xticks(axd['D'].get_xticks(), axd['D'].get_xticklabels(), rotation=90)\n",
    "axd['D'].set_yticks(axd['D'].get_yticks(), axd['D'].get_yticklabels(), rotation=0)\n",
    "axd['X'].set_ylabel('Average precision', rotation=270, fontsize=default_fontsize, labelpad=30)\n",
    "axd['X'].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1], ['0.0', '0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=default_fontsize)\n",
    "\n",
    "\n",
    "sns.heatmap(excluded_df.loc[location_order, stat_order], \n",
    "            vmin=min_val,\n",
    "            vmax=max_val,\n",
    "            cmap=custom_coolwarm_cmap, \n",
    "            annot=excluded_text_df.loc[location_order, stat_order],\n",
    "            fmt='', \n",
    "            annot_kws={\"size\": small_fontsize},\n",
    "            ax=axd['E'],\n",
    "            cbar_ax=axd['Y'],)\n",
    "\n",
    "\n",
    "axd['E'].tick_params(labelsize=default_fontsize)\n",
    "axd['E'].set_xticks(axd['E'].get_xticks(), axd['E'].get_xticklabels(),  rotation=90)\n",
    "axd['E'].set_yticks(axd['E'].get_yticks(), axd['E'].get_yticklabels(), rotation=0)\n",
    "axd['Y'].set_ylabel('Δ Average precision', rotation=270, fontsize=default_fontsize, labelpad=30)\n",
    "axd['Y'].set_yticks([0, 0.005, 0.01, 0.015], ['0.000', '0.005', '0.010', '0.015'], fontsize=default_fontsize)\n",
    "\n",
    "\n",
    "axd['A'].text(-0.2, 2.09, 'a', fontsize=big_fontsize, fontweight='bold', transform=axd['C'].transAxes)\n",
    "axd['B'].text(-0.2, 2.09, 'b', fontsize=big_fontsize, fontweight='bold', transform=axd['D'].transAxes)\n",
    "axd['C'].text(-0.2, 1.05, 'c', fontsize=big_fontsize, fontweight='bold', transform=axd['C'].transAxes)\n",
    "axd['D'].text(-0.2, 1.05, 'd', fontsize=big_fontsize, fontweight='bold', transform=axd['D'].transAxes)\n",
    "axd['E'].text(-0.2, 1.05, 'e', fontsize=big_fontsize, fontweight='bold', transform=axd['E'].transAxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3898b",
   "metadata": {},
   "source": [
    "### Fig 3\n",
    "\n",
    "A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder = joblib.load(f'{project_path}/label_encoder.joblib')\n",
    "\n",
    "quantcell_labels = pd.read_csv(f'{project_path}/quantcell_labels.csv').iloc[:, 0]\n",
    "quantcell_true = pd.read_csv(f'{project_path}/quantcell_true_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "# rows are true labels, columns are predicted labels\n",
    "\n",
    "confusion_matrix_quantcell = confusion_matrix(quantcell_true, quantcell_labels, labels=encoder.classes_)\n",
    "confusion_matrix_quantcell = pd.DataFrame(confusion_matrix_quantcell, \n",
    "                              index=encoder.classes_, \n",
    "                              columns=encoder.classes_)\n",
    "\n",
    "confusion_matrix_quantcell = confusion_matrix_quantcell.loc[cell_order, cell_order] # reorder rows and columns\n",
    "\n",
    "other_mask = quantcell_labels != 'Other'\n",
    "\n",
    "scores=precision_score(quantcell_true[other_mask], quantcell_labels[other_mask], average=None)\n",
    "print('Minimum cell-type precision score for QuantCell:', min(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef128ca",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ad0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_annotated = joblib.load(f'{project_path}/fraction_annotated.joblib')\n",
    "\n",
    "percent_increase = (fraction_annotated['FDR < 5%']) / fraction_annotated['Conventional'] * 100\n",
    "print(f'Percent increase in fraction annotated: {percent_increase:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22440c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_annotated['Conventional']+fraction_annotated['FDR < 5%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_annotated['Conventional']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9348151",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b54972",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_codex = pd.read_csv(f'{project_path}/codex_conventional_QuantCellPaper.csv', index_col=0)\n",
    "relabeled_codex = pd.read_csv(f'{project_path}/codex_quantcell_QuantCellPaper.csv', index_col=0)\n",
    "\n",
    "original_frequencies = original_codex.loc[:, 'cell_type'].value_counts()/len(original_codex)\n",
    "relabeled_frequencies = relabeled_codex.loc[:, 'cell_type'].value_counts()/len(relabeled_codex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_codex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228166b0",
   "metadata": {},
   "source": [
    "D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "facs_data = pd.read_csv(f'{data_path}/OldYoungRound1FACS.csv', index_col=0)\n",
    "\n",
    "facs_data.loc[:, 'Mouse ID'] = ['O1', 'O2', 'O3', 'Y1', 'Y2', 'Y3']\n",
    "facs_data.set_index('Mouse ID', inplace=True, drop=True)\n",
    "\n",
    "for x in facs_data.columns:\n",
    "    facs_data.rename(columns={x: x.split(' ')[0]}, inplace=True)\n",
    "    x= x.split(' ')[0]\n",
    "\n",
    "    facs_data.rename(columns={x: x.split('+')[0]}, inplace=True)\n",
    "    x= x.split('+')[0]\n",
    "    if x in ['T', 'B']:\n",
    "        facs_data.rename(columns={x: x + ' Cells'}, inplace=True)\n",
    "\n",
    "    if x in ['CD4', 'CD8']:\n",
    "        facs_data.rename(columns={x: x + ' T Cells'}, inplace=True)\n",
    "    \n",
    "facs_data.loc[:, 'MPP'] = facs_data.loc[:, 'KLS'] - facs_data.loc[:, 'HSC']\n",
    "# CLP gating strategy is not the same as we use for cell annotation, so we will not use it\n",
    "facs_data.drop(columns=['Granulocytes', 'FLK2', 'FLK2-', 'HSC', 'Progenitor', 'Lineage-', 'MPP', 'T Cells', 'CLP'], inplace=True)\n",
    "facs_data /= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba62c4b",
   "metadata": {},
   "source": [
    "E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ba73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annospat_labels = pd.read_csv(f'{project_path}/AnnoSpat/outputdir/trte_labels_ELM_IMC_T1D_AnnoSpat.csv', index_col=0).loc[:, 'label']\n",
    "annospat_true = pd.read_csv(f'{project_path}/AnnoSpat/annospat_true_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "\n",
    "maps_labels = pd.read_csv(f'{project_path}/MAPS/results/cell_phenotyping/pred_labels.csv', index_col=0).iloc[:, 0]\n",
    "maps_true = pd.read_csv(f'{project_path}/MAPS/data/cell_phenotyping/test_features.csv', index_col=0).loc[:, 'cell_label']\n",
    "\n",
    "maps_labels = encoder.inverse_transform(maps_labels)\n",
    "maps_true = encoder.inverse_transform(maps_true)\n",
    "\n",
    "quantcell_labels = pd.read_csv(f'{project_path}/quantcell_labels.csv').iloc[:, 0]\n",
    "quantcell_true = pd.read_csv(f'{project_path}/quantcell_true_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "\n",
    "astir_labels = pd.read_csv(f'{project_path}/Astir/astir_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "astir_true = pd.read_csv(f'{project_path}/Astir/astir_true_labels.csv').loc[:, 'cell_type']\n",
    "\n",
    "annospat = balanced_accuracy_score(annospat_true, annospat_labels)\n",
    "maps = balanced_accuracy_score(maps_true, maps_labels)\n",
    "quantcell_other_mask = quantcell_labels != 'Other'\n",
    "quantcell = balanced_accuracy_score(quantcell_true[quantcell_other_mask], quantcell_labels[quantcell_other_mask])\n",
    "astir = balanced_accuracy_score(astir_true, astir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fontsize=22\n",
    "small_fontsize=14\n",
    "big_fontsize=30\n",
    "plt.rcParams['font.size'] = default_fontsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17, 22))\n",
    "axd={}\n",
    "axd['A'] = fig.add_subplot(3, 3, 1)\n",
    "axd['X'] = fig.add_subplot(3, 3, 2)\n",
    "axd['B'] = fig.add_subplot(3, 3, 3)\n",
    "axd['C'] = fig.add_subplot(3, 3, 4)\n",
    "axd['D'] = fig.add_subplot(3, 3, 5)\n",
    "axd['E'] = fig.add_subplot(3, 3, 7)\n",
    "\n",
    "\n",
    "axd['A'].set_position([0.1, 0.725, 0.25, 0.205])\n",
    "axd['X'].set_position([0.37, 0.725, 0.02, 0.205])\n",
    "axd['B'].set_position([0.55, 0.7, 0.45, 0.23])\n",
    "\n",
    "axd['C'].set_position([0.05, 0.35, 0.35, 0.193])\n",
    "axd['D'].set_position([0.55, 0.35, 0.4, 0.193])\n",
    "\n",
    "axd['E'].set_position([0.05, 0.1, 0.4, 0.15])\n",
    "\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix_quantcell, 'QuantCell', normalization='col', ax=axd['A'], cbar_ax=axd['X'])\n",
    "\n",
    "\n",
    "axd['A'].set_xticklabels((axd['A'].get_xticklabels()), fontsize=small_fontsize, rotation=90)\n",
    "axd['A'].set_yticklabels((axd['A'].get_yticklabels()), fontsize=small_fontsize, rotation=0)\n",
    "axd['A'].set_ylabel('Conventional annotation', fontsize=default_fontsize)\n",
    "axd['A'].set_xlabel('QuantCell', fontsize=default_fontsize)\n",
    "\n",
    "base = fraction_annotated['Conventional']\n",
    "labels = ['Conventional\\nannotation', 'FDR < 1%', 'FDR < 5%', 'FDR < 10%']\n",
    "\n",
    "axd['B'].bar(range(len(labels)), \n",
    "       height=base, \n",
    "       color='white', \n",
    "       alpha=1,\n",
    "       edgecolor='black')\n",
    "\n",
    "axd['B'].bar(range(len(labels)), \n",
    "       height=base, \n",
    "       color='blue', \n",
    "       alpha=0.5,\n",
    "       edgecolor='black')\n",
    "\n",
    "axd['B'].bar(range(len(labels)), \n",
    "       height=[0] + [fraction_annotated[x] for x in labels[1:]], \n",
    "       bottom=base, \n",
    "       color='white', \n",
    "       alpha=1,\n",
    "       edgecolor='black')\n",
    "\n",
    "axd['B'].bar(range(len(labels)), \n",
    "       height=[0] + [fraction_annotated[x] for x in labels[1:]], \n",
    "       bottom=base, \n",
    "       color='green', \n",
    "       alpha=0.5,\n",
    "       edgecolor='black')\n",
    "\n",
    "green_patch = mpatches.Patch(facecolor=(0,0.5,0,0.5), label='QuantCell', edgecolor=(0,0,0,1))\n",
    "blue_patch = mpatches.Patch(facecolor=(0,0,1,0.5), label='Conventional annotation', edgecolor=(0,0,0,1))\n",
    "\n",
    "axd['B'].legend(handles=[blue_patch, green_patch], fontsize=default_fontsize, frameon=False, bbox_transform=axd['B'].transAxes, bbox_to_anchor=(0.05, 1.15), loc='upper left')\n",
    "axd['B'].set_ylim([0, 1])\n",
    "axd['B'].set_xticks(range(len(labels)),  labels=labels)\n",
    "axd['B'].set_ylabel('Fraction annotated', fontsize=default_fontsize)\n",
    "axd['B'].spines[['right', 'top']].set_visible(False)\n",
    "axd['B'].tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "index = relabeled_frequencies.index[relabeled_frequencies.index != 'Other']\n",
    "xvals = original_frequencies[original_frequencies.index.isin(index)]\n",
    "yvals = relabeled_frequencies[relabeled_frequencies.index.isin(index)]\n",
    "axd['C'].scatter(xvals, yvals, s=20, color='black')\n",
    "axd['C'].set_xlabel('Conventional annotation frequency', fontsize=default_fontsize)\n",
    "axd['C'].set_ylabel('QuantCell frequency', fontsize=default_fontsize)\n",
    "axd['C'].tick_params(labelsize=default_fontsize)\n",
    "r, p = pearsonr(xvals, yvals)\n",
    "axd['C'].set_title(f'r={str(r)[:5]}   $p$-value={p:.2}', fontsize=default_fontsize)\n",
    "axd['C'].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "a, b = np.polyfit(xvals.sort_values(), yvals[xvals.sort_values().index], 1)\n",
    "axd['C'].plot(xvals.sort_values(), a * xvals.sort_values() + b, color='grey', linestyle='--')\n",
    "\n",
    "axd['C'].set_xlim([-0.002, None])\n",
    "axd['C'].set_ylim([-0.005, None])\n",
    "\n",
    "cells_of_interest = [x for x in cell_order if x in facs_data.columns and x in original_frequencies.index and x in relabeled_frequencies.index]\n",
    "\n",
    "\n",
    "xvals = facs_data.loc[:, cells_of_interest].mean()\n",
    "yvals = relabeled_frequencies[cells_of_interest]\n",
    "axd['D'].scatter(xvals, yvals, s=20, color='black')\n",
    "axd['D'].set_xlabel('Flow cytometry frequency', fontsize=default_fontsize)\n",
    "axd['D'].set_ylabel('QuantCell frequency', fontsize=default_fontsize)\n",
    "axd['D'].tick_params(labelsize=default_fontsize)\n",
    "r, p = pearsonr(xvals, yvals)\n",
    "axd['D'].set_title(f'r={str(r)[:5]}   $p$-value={p:.4f}', fontsize=default_fontsize)\n",
    "axd['D'].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "a, b = np.polyfit(xvals.sort_values(), yvals[xvals.sort_values().index], 1)\n",
    "axd['D'].plot(xvals.sort_values(), a * xvals.sort_values() + b, color='grey', linestyle='--')\n",
    "axd['D'].set_xlim([-0.001, 0.08])\n",
    "axd['D'].set_ylim([-0.003, None])\n",
    "\n",
    "\n",
    "axd['E'].bar(['Astir', 'AnnoSpat', 'MAPS', 'QuantCell'], \n",
    "       [astir, annospat, maps, quantcell], \n",
    "       color='white', \n",
    "       edgecolor='black',\n",
    "       alpha=1)    \n",
    "\n",
    "axd['E'].bar(['Astir', 'AnnoSpat', 'MAPS', 'QuantCell'], \n",
    "       [astir, annospat, maps, quantcell], \n",
    "       color=['crimson', 'purple', 'orange', 'green'], \n",
    "       edgecolor='black',\n",
    "       alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "axd['E'].set_ylabel('Balanced accuracy', fontsize=default_fontsize)\n",
    "axd['E'].tick_params(labelsize=default_fontsize)\n",
    "axd['E'].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1], fontsize=default_fontsize)\n",
    "axd['E'].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "for i, score in enumerate([astir, annospat, maps, quantcell]):\n",
    "    axd['E'].text(i-0.23, score + 0.01, f'{score:.3f}', fontsize=default_fontsize, color='black')\n",
    "\n",
    "axd['A'].text(-0.2, 3.064, 'a', fontsize=big_fontsize, fontweight='bold', transform=axd['C'].transAxes)\n",
    "axd['B'].text(-0.15, 1.05, 'b', fontsize=big_fontsize, fontweight='bold', transform=axd['B'].transAxes)\n",
    "axd['C'].text(-0.2, 1.093, 'c', fontsize=big_fontsize, fontweight='bold', transform=axd['C'].transAxes)\n",
    "axd['D'].text(-0.15, 1.093, 'd', fontsize=big_fontsize, fontweight='bold', transform=axd['D'].transAxes)\n",
    "axd['E'].text(-0.15, 1.05, 'e', fontsize=big_fontsize, fontweight='bold', transform=axd['E'].transAxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04b721",
   "metadata": {},
   "source": [
    "### Fig 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a7406",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b798a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = joblib.load(f'{project_path}/model_selection/top3models_results.joblib')\n",
    "encoder = joblib.load(f'{project_path}/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred, y_proba=results['RandomForestClassifier_tuned']\n",
    "score_matrix = np.zeros((len(encoder.classes_), 10))\n",
    "for n in range(10):\n",
    "    score_matrix[:, n] = f1_score(y_test[n], y_pred[n], average=None)\n",
    "\n",
    "f1_scores = {}\n",
    "for i, label in enumerate(encoder.classes_):\n",
    "    f1_scores[label] = np.mean(score_matrix[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_dir = '/store/Projects/wboohar/PhenoCycler/' \n",
    "project_name = 'QuantCellPaper'\n",
    "\n",
    "project = quantcell_project()\n",
    "project.initialize(base_path=base_dir, project_name=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict={}\n",
    "size_dict={}\n",
    "number_marker_dict={}\n",
    "circularity_dict={}\n",
    "\n",
    "marker_combos = read_marker_combos(annotations_path)\n",
    "\n",
    "total_annotated = project.codex.loc[:, 'cell_type'].value_counts().sum() - project.codex.loc[:, 'cell_type'].value_counts()['Other']\n",
    "\n",
    "for ct in cell_order:\n",
    "    mask = project.codex.loc[:, 'cell_type'] == ct\n",
    "    frequency_dict[ct] = project.codex.loc[mask, 'cell_type'].value_counts()[ct] / total_annotated\n",
    "    size_dict[ct] = project.codex.loc[mask, 'Cell: Area µm^2'].mean()\n",
    "    circularity_dict[ct] = project.codex.loc[mask, 'Cell: Circularity'].mean()\n",
    "    number_marker_dict[ct] = len(marker_combos[ct])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ko_dict = joblib.load(f'{project_path}/model_selection/gene_ko_dict.joblib')\n",
    "tuned_predictions = joblib.load(f'{project_path}/model_selection/top3models_results.joblib')['RandomForestClassifier_tuned']\n",
    "gene_order = sorted(gene_ko_dict.keys(), key=str.lower)\n",
    "f1_baseline = np.mean([f1_score(tuned_predictions[0][n], tuned_predictions[1][n], average=None) for n in range(10)], axis=0)\n",
    "\n",
    "f1_matrix = np.zeros((len(gene_order), 10, len(encoder.classes_)))\n",
    "for n, gene in enumerate(gene_order):\n",
    "    for fold in range(10):\n",
    "        y_true = gene_ko_dict[gene][0][fold]\n",
    "        y_pred = gene_ko_dict[gene][1][fold]\n",
    "        f1_matrix[n, fold, :] = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "\n",
    "long_df = pd.DataFrame(columns=['Gene', 'Fold', 'Cell Type', 'F1 Score'])\n",
    "for n, gene in enumerate(gene_order):\n",
    "    for fold in range(10):\n",
    "        for cell_type in encoder.classes_:\n",
    "            cell_index = encoder.transform([cell_type])[0]\n",
    "            long_df = long_df.append({\n",
    "                'Gene': gene,\n",
    "                'Fold': fold,\n",
    "                'Cell Type': cell_type,\n",
    "                'F1 Score': f1_matrix[n, fold, cell_index] - f1_baseline[cell_index]\n",
    "            }, ignore_index=True)\n",
    "\n",
    "marker_combos = read_marker_combos(annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac224ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(17, 22))\n",
    "axs=axs.flatten()\n",
    "\n",
    "axs[0].set_position([0.05, 0.75, 0.4, 0.13])\n",
    "axs[1].set_position([0.55, 0.75, 0.4, 0.13])\n",
    "axs[2].set_position([0.05, 0.53, 0.4, 0.13])\n",
    "axs[3].set_position([0.55, 0.53, 0.4, 0.13])\n",
    "\n",
    "axs[4].set_position([0.05, 0.28, 0.4, 0.18])\n",
    "axs[5].set_position([0.55, 0.28, 0.4, 0.18])\n",
    "axs[6].set_position([0.05, 0.05, 0.4, 0.18])\n",
    "axs[7].set_position([0.55, 0.05, 0.4, 0.18])\n",
    "\n",
    "\n",
    "axs[0].scatter([frequency_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order], color='black')\n",
    "axs[0].set_xlabel('Cell frequency', fontsize=default_fontsize)\n",
    "axs[0].set_ylabel('F1 score', fontsize=default_fontsize)\n",
    "axs[0].spines[['top', 'right']].set_visible(False)\n",
    "axs[0].tick_params(labelsize=default_fontsize)\n",
    "axs[0].set_xlim(0, 0.3)\n",
    "axs[0].set_ylim(0.68, 1)\n",
    "stat, pvalue = pearsonr([frequency_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order])\n",
    "axs[0].text(0.20, 1.05, f'r= {stat:.2f}       $p$-value={pvalue:.3f}', fontsize=default_fontsize, transform=axs[0].transAxes)\n",
    "\n",
    "axs[1].scatter([size_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order], color='black')\n",
    "axs[1].set_xlabel('Cell size (µm²)', fontsize=default_fontsize)\n",
    "axs[1].spines[['top', 'right']].set_visible(False)\n",
    "axs[1].tick_params(labelsize=default_fontsize)\n",
    "stat, pvalue = pearsonr([size_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order])\n",
    "axs[1].text(0.20, 1.05, f'r= {stat:.2f}       $p$-value={pvalue:.3f}', fontsize=default_fontsize, transform=axs[1].transAxes)\n",
    "\n",
    "axs[2].scatter([circularity_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order], color='black')\n",
    "axs[2].set_xlabel('Cell circularity', fontsize=default_fontsize)\n",
    "axs[2].set_ylabel('F1 score', fontsize=default_fontsize)\n",
    "axs[2].spines[['top', 'right']].set_visible(False)\n",
    "axs[2].tick_params(labelsize=default_fontsize)\n",
    "stat, pvalue = pearsonr([circularity_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order])\n",
    "axs[2].text(0.20, 1.05, f'r= {stat:.2f}       $p$-value={pvalue:.3f}', fontsize=default_fontsize, transform=axs[2].transAxes)\n",
    "\n",
    "axs[3].scatter([number_marker_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order], color='black')\n",
    "axs[3].set_xlabel('Number of markers', fontsize=default_fontsize)\n",
    "axs[3].spines[['top', 'right']].set_visible(False)\n",
    "axs[3].tick_params(labelsize=default_fontsize)\n",
    "stat, pvalue = pearsonr([number_marker_dict[ct] for ct in cell_order], [f1_scores[ct] for ct in cell_order])\n",
    "axs[3].text(0.20, 1.05, f'r= {stat:.2f}       $p$-value={pvalue:.3f}', fontsize=default_fontsize, transform=axs[3].transAxes)\n",
    "\n",
    "\n",
    "for i, ct in enumerate(['KLS', 'Erythrocytes', 'Arterial ECs', 'CD8 T Cells']):\n",
    "    sns.swarmplot(data=long_df[long_df['Cell Type'] == ct],\n",
    "                   x='Gene',\n",
    "                   y='F1 Score',\n",
    "                   ax=axs[4+i],\n",
    "                   color='black',\n",
    "                   size=4)\n",
    "    axs[4+i].spines[['top', 'right']].set_visible(False)\n",
    "    axs[4+i].set_title(f'{ct}', fontsize=default_fontsize)\n",
    "    axs[4+i].axhline(0, color='black', linestyle='--', linewidth=2)\n",
    "    axs[4+i].set_ylabel('Δ F1 Score', fontsize=default_fontsize)\n",
    "    \n",
    "    axs[4+i].set_xticklabels([' ']*len(gene_order), fontsize=default_fontsize)\n",
    "    axs[4+i].tick_params(labelsize=default_fontsize)\n",
    "    mean_std = long_df.groupby(['Gene', 'Cell Type']).std().groupby('Cell Type').mean().loc[ct]\n",
    "    offset=-1\n",
    "    ylim=0\n",
    "    for n, gene in enumerate(gene_order):\n",
    "       \n",
    "        mean_difference = long_df[(long_df['Gene'] == gene) & (long_df['Cell Type'] == ct)]['F1 Score'].mean()\n",
    "        min_difference = long_df[(long_df['Gene'] == gene) & (long_df['Cell Type'] == ct)]['F1 Score'].min()\n",
    "\n",
    "        if np.abs(mean_difference) > 3*mean_std.values[0]:\n",
    "            if n < 5:\n",
    "                offset = 1\n",
    "            if n > len(gene_order) - 4:\n",
    "                offset = -1\n",
    "            if gene == 'Endomucin':\n",
    "                offset = 1\n",
    "            axs[4+i].text(gene_order.index(gene) + 1.6*offset + 0.2*len(gene)*offset, 1.1*min_difference, gene, fontsize=default_fontsize, ha='center', va='bottom')\n",
    "            offset *= -1\n",
    "        if min_difference < ylim:\n",
    "            ylim = min_difference\n",
    "    axs[4+i].set_ylim([1.2*ylim, None])\n",
    "\n",
    "axs[4].set_xlabel('', fontsize=default_fontsize)\n",
    "axs[5].set_xlabel('', fontsize=default_fontsize)\n",
    "\n",
    "axs[6].set_xlabel('Gene excluded', fontsize=default_fontsize)\n",
    "axs[7].set_xlabel('Gene excluded', fontsize=default_fontsize)\n",
    "axs[6].set_title('Arterial ECs', fontsize=default_fontsize)\n",
    "\n",
    "\n",
    "axs[0].text(-0.15, 1.1, 'a', fontsize=big_fontsize, fontweight='bold', transform=axs[0].transAxes)\n",
    "axs[4].text(-0.15, 1.1, 'b', fontsize=big_fontsize, fontweight='bold', transform=axs[4].transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be09137",
   "metadata": {},
   "source": [
    "## S1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_model_names = [\n",
    "    'Nearest Neighbors',\n",
    "    'Multilayer Perceptron',\n",
    "    'Random Forest',\n",
    "    'Extra Trees',\n",
    "    'Decision Tree',\n",
    "    'Gaussian Naive-Bayes',\n",
    "    'Ridge Classifier',\n",
    "    \"Linear SVC\"\n",
    "]\n",
    "\n",
    "color_dict = {\n",
    "    'Nearest Neighbors': '#1f77b4',\n",
    "    'Multilayer Perceptron': 'mediumslateblue',\n",
    "    'Random Forest': '#2ca02c',\n",
    "    'Extra Trees': '#d62728',\n",
    "    'Decision Tree': 'darkgoldenrod',\n",
    "    'Gaussian Naive-Bayes': '#8c564b',\n",
    "    'Ridge Classifier': 'darkcyan',\n",
    "    \"Linear SVC\": '#e377c2'\n",
    "}\n",
    "\n",
    "\n",
    "fig,axs = plt.subplots(2, 1, figsize=(12, 14))\n",
    "axs=axs.flatten()\n",
    "\n",
    "\n",
    "if not 'base_names_sorted' in globals():\n",
    "    base_names_sorted = ['Random Forest', 'Multilayer Perceptron', 'Extra Trees', 'Linear SVC', 'Nearest Neighbors', 'Decision Tree', 'Ridge Classifier', 'Gaussian Naive-Bayes'][::-1]\n",
    "\n",
    "for n, model in enumerate(base_names_sorted):\n",
    "    time_elapsed = joblib.load(f'{project_path}/base_models/{model}_time_elapsed.joblib')\n",
    "\n",
    "    time_elapsed = time_elapsed / 10 # average over 10 folds\n",
    "\n",
    "    print(f'{model} time elapsed: {time_elapsed:.2f} seconds')\n",
    "    axs[0].barh(n, time_elapsed, color=color_dict[model], label=model, alpha=0.6, edgecolor='black')\n",
    "    axs[0].text(time_elapsed*1.05, n, f'{time_elapsed:.2f}', va='center', fontsize=default_fontsize)\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].spines[['top', 'right']].set_visible(False)\n",
    "axs[0].set_xlabel('Training time (seconds)', fontsize=default_fontsize)\n",
    "\n",
    "def sentence_case(names):\n",
    "    temp = [name.lower() for name in names]\n",
    "    temp = [name[0].upper() + name[1:] for name in temp]\n",
    "    temp = [name.replace('svc', 'SVC') for name in temp]  # Keep SVC as is\n",
    "    return temp\n",
    "\n",
    "axs[0].set_yticks(range(len(base_names_sorted)), sentence_case(base_names_sorted), fontsize=default_fontsize)\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=default_fontsize)\n",
    "axs[0].set_xticks([1, 10, 100, 1000], [1, 10, 100, 1000], fontsize=default_fontsize)\n",
    "\n",
    "\n",
    "names_sorted = ['Astir', 'AnnoSpat', 'MAPS', 'QuantCell'][::-1]\n",
    "\n",
    "astir_time = pd.read_csv(f'{project_path}/Astir/astir_time.csv', index_col=0).iloc[0, 0]\n",
    "with open(f'{project_path}/AnnoSpat/time_elapsed.txt', 'r') as f:\n",
    "    annospat_time = float(f.read().strip())/10**9 # convert from nanoseconds to seconds\n",
    "maps_time = pd.read_csv(f'{project_path}/MAPS/results/cell_phenotyping/time_elapsed_maps.csv', index_col=0).iloc[0, 0]\n",
    "quantcell_time = pd.read_csv(f'{project_path}/time_elapsed_quantcell.csv').iloc[0, 0]\n",
    "\n",
    "\n",
    "axs[1].barh(range(len(names_sorted)),\n",
    "        [astir_time, annospat_time, maps_time, quantcell_time][::-1],\n",
    "        color='white', label='Training time', alpha=1, edgecolor='black')\n",
    "axs[1].barh(range(len(names_sorted)),\n",
    "        [astir_time, annospat_time, maps_time, quantcell_time][::-1],\n",
    "        color=['crimson', 'purple', 'orange', 'green'][::-1], label='Training time', alpha=0.5, edgecolor='black')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].spines[['top', 'right']].set_visible(False)\n",
    "axs[1].set_xlabel('Annotation runtime (seconds)', fontsize=default_fontsize)\n",
    "axs[1].set_yticks(range(len(names_sorted)), names_sorted, fontsize=default_fontsize)\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=default_fontsize)\n",
    "axs[1].set_xticks([1, 10, 100, 1000, 10000], [1, 10, 100, 1000, 10000], fontsize=default_fontsize)\n",
    "axs[1].text(astir_time*1.1, 3, f'{astir_time:.2f}', fontsize=default_fontsize, color='black', va='center')\n",
    "axs[1].text(annospat_time*1.1, 2, f'{annospat_time:.2f}', fontsize=default_fontsize, color='black', va='center')\n",
    "axs[1].text(maps_time*1.1, 1, f'{maps_time:.2f}', fontsize=default_fontsize, color='black', va='center')\n",
    "axs[1].text(quantcell_time*1.1, 0, f'{quantcell_time:.2f}', fontsize=default_fontsize, color='black', va='center')\n",
    "\n",
    "\n",
    "axs[0].text(-0.1, 1.05, 'a', fontsize=big_fontsize, fontweight='bold', transform=axs[0].transAxes)\n",
    "axs[1].text(-0.1, 1.05, 'b', fontsize=big_fontsize, fontweight='bold', transform=axs[1].transAxes)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a3f8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdcfe158",
   "metadata": {},
   "source": [
    "## S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fontsize=22\n",
    "small_fontsize=14\n",
    "big_fontsize=30\n",
    "plt.rcParams['font.size'] = default_fontsize\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(18, 18))\n",
    "axs=axs.flatten()\n",
    "\n",
    "axs[0].set_position([0.05, 0.45, 0.23, 0.23])\n",
    "axs[1].set_position([0.30, 0.45, 0.02, 0.23])\n",
    "axs[2].set_position([0.55, 0.45, 0.23, 0.23])\n",
    "axs[3].set_position([0.80, 0.45, 0.02, 0.23])\n",
    "\n",
    "axs[4].set_position([0.05, 0.05, 0.23, 0.23])\n",
    "axs[5].set_position([0.30, 0.05, 0.02, 0.23])\n",
    "axs[6].set_position([0.55, 0.05, 0.23, 0.23])\n",
    "axs[7].set_position([0.80, 0.05, 0.02, 0.23])\n",
    "\n",
    "\n",
    "# rows are true labels, columns are predicted labels\n",
    "\n",
    "annospat_labels = pd.read_csv(f'{project_path}/AnnoSpat/outputdir/trte_labels_ELM_IMC_T1D_AnnoSpat.csv', index_col=0).loc[:, 'label']\n",
    "annospat_true = pd.read_csv(f'{project_path}/AnnoSpat/annospat_true_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "\n",
    "confusion_matrix_annospat = confusion_matrix(annospat_true, annospat_labels, labels=encoder.classes_)\n",
    "confusion_matrix_annospat = pd.DataFrame(confusion_matrix_annospat, \n",
    "                              index=encoder.classes_, \n",
    "                              columns=encoder.classes_)\n",
    "\n",
    "confusion_matrix_annospat = confusion_matrix_annospat.loc[cell_order, cell_order] # reorder rows and columns\n",
    "\n",
    "maps_labels = pd.read_csv(f'{project_path}/MAPS/results/cell_phenotyping/pred_labels.csv', index_col=0).iloc[:, 0]\n",
    "maps_true = pd.read_csv(f'{project_path}/MAPS/data/cell_phenotyping/test_features.csv', index_col=0).loc[:, 'cell_label']\n",
    "\n",
    "maps_labels = encoder.inverse_transform(maps_labels)\n",
    "maps_true = encoder.inverse_transform(maps_true)\n",
    "\n",
    "confusion_matrix_maps = confusion_matrix(maps_true, maps_labels, labels=encoder.classes_)\n",
    "confusion_matrix_maps = pd.DataFrame(confusion_matrix_maps, \n",
    "                              index=encoder.classes_, \n",
    "                              columns=encoder.classes_)\n",
    "\n",
    "confusion_matrix_maps = confusion_matrix_maps.loc[cell_order, cell_order] # reorder rows and columns\n",
    "\n",
    "\n",
    "astir_labels = pd.read_csv(f'{project_path}/Astir/astir_labels.csv', index_col=0).loc[:, 'cell_type']\n",
    "astir_true = pd.read_csv(f'{project_path}/Astir/astir_true_labels.csv').loc[:, 'cell_type']\n",
    "\n",
    "confusion_matrix_astir = confusion_matrix(astir_true, astir_labels, labels=(encoder.classes_))\n",
    "confusion_matrix_astir = pd.DataFrame(confusion_matrix_astir, \n",
    "                              index=encoder.classes_, \n",
    "                              columns=encoder.classes_)\n",
    "\n",
    "confusion_matrix_astir = confusion_matrix_astir.loc[cell_order, cell_order] # reorder rows and columns\n",
    "\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix_astir, 'Astir', normalization='col', ax=axs[0], cbar_ax=axs[1])\n",
    "plot_confusion_matrix(confusion_matrix_annospat, 'AnnoSpat', normalization='col', ax=axs[2], cbar_ax=axs[3])\n",
    "plot_confusion_matrix(confusion_matrix_maps, 'MAPS', normalization='col', ax=axs[4], cbar_ax=axs[5])\n",
    "\n",
    "axs[0].set_xticklabels((axs[0].get_xticklabels()), fontsize=small_fontsize, rotation=90)\n",
    "axs[0].set_yticklabels((axs[0].get_yticklabels()), fontsize=small_fontsize, rotation=0)\n",
    "axs[0].set_ylabel('Conventional annotation', fontsize=default_fontsize)\n",
    "axs[0].set_xlabel('Astir', fontsize=default_fontsize)\n",
    "\n",
    "axs[2].set_xticklabels((axs[2].get_xticklabels()), fontsize=small_fontsize, rotation=90)\n",
    "axs[2].set_yticklabels((axs[2].get_yticklabels()), fontsize=small_fontsize, rotation=0)\n",
    "axs[2].set_ylabel('Conventional annotation', fontsize=default_fontsize)\n",
    "axs[2].set_xlabel('AnnoSpat', fontsize=default_fontsize)\n",
    "\n",
    "axs[4].set_xticklabels((axs[4].get_xticklabels()), fontsize=small_fontsize, rotation=90)\n",
    "axs[4].set_yticklabels((axs[4].get_yticklabels()), fontsize=small_fontsize, rotation=0)\n",
    "axs[4].set_ylabel('Conventional annotation', fontsize=default_fontsize)\n",
    "axs[4].set_xlabel('MAPS', fontsize=default_fontsize)\n",
    "\n",
    "axs[6].set_visible(False)\n",
    "axs[7].set_visible(False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulab-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
