{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import yaml\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "os.chdir('/home/LULAB/wboohar/CODEX/data_processing/code')\n",
    "from codex_project import codex_project\n",
    "from quantcell import quantcell_project, interpolate_PRC\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = '/store/Projects/wboohar/PhenoCycler/annotation_strategies/marker_combos_062525_updated_verified.json'   \n",
    "base_dir = '/store/Projects/wboohar/PhenoCycler' \n",
    "project_name = 'QuantCellPaper'\n",
    "project_path = f'{base_dir}/{project_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = quantcell_project()\n",
    "project.initialize(base_path=base_dir, project_name=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa742576",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2fc04",
   "metadata": {},
   "source": [
    "### Create data for Fig 2A-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = [\n",
    "    'Nearest Neighbors',\n",
    "    'Multilayer Perceptron',\n",
    "    'Random Forest',\n",
    "    'Extra Trees',\n",
    "    'Decision Tree',\n",
    "    'Gaussian Naive-Bayes',\n",
    "    'Ridge Regression',\n",
    "    \"Linear SVC\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    MLPClassifier(),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    ExtraTreesClassifier(n_jobs=-1),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    RidgeClassifier(),\n",
    "    OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16865a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.test_model_list(classifiers, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(f'{base_dir}/{project_name}/base_models/', exist_ok=True)\n",
    "\n",
    "base_clf_performance_dict={}\n",
    "    \n",
    "for _name in names:\n",
    "    y_test = joblib.load(f'{base_dir}/{project_name}/base_models/{_name}_y_test.joblib')\n",
    "    y_pred = joblib.load(f'{base_dir}/{project_name}/base_models/{_name}_y_pred.joblib')\n",
    "    y_proba = joblib.load(f'{base_dir}/{project_name}/base_models/{_name}_y_proba.joblib')\n",
    "\n",
    "    macro_AP_list = []\n",
    "    weighted_AP_list = []\n",
    "    macro_interp_PRC_list = []\n",
    "    weighted_interp_PRC_list = []\n",
    "\n",
    "    for fold in range(10):\n",
    "        \n",
    "\n",
    "        macro_AP = average_precision_score(y_test[fold], y_proba[fold], average='macro')\n",
    "        weighted_AP = average_precision_score(y_test[fold], y_proba[fold], average='weighted')\n",
    "\n",
    "        macro_interp_PRC = interpolate_PRC(y_test[fold], y_pred[fold], y_proba[fold], average='macro')\n",
    "        weighted_interp_PRC = interpolate_PRC(y_test[fold], y_pred[fold], y_proba[fold], average='weighted')\n",
    "\n",
    "        macro_AP_list.append(macro_AP)\n",
    "        weighted_AP_list.append(weighted_AP)\n",
    "        \n",
    "        macro_interp_PRC_list.append(macro_interp_PRC)\n",
    "        weighted_interp_PRC_list.append(weighted_interp_PRC)\n",
    "\n",
    "    all_y_test = np.concatenate([y_test[x] for x in range(10)])\n",
    "    num_classes = len(np.unique(all_y_test))\n",
    "\n",
    "    base_clf_performance_dict[_name] = [macro_AP_list, weighted_AP_list, macro_interp_PRC_list, weighted_interp_PRC_list, num_classes]\n",
    "\n",
    "joblib.dump(base_clf_performance_dict, f'{base_dir}/{project_name}/base_models/base_clf_performance_dict.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1addd3a",
   "metadata": {},
   "source": [
    "2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048078ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space_MLP = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,), (300,), (400,), (500,), (100,50), (200,50), (50, 50, 50), (50, 100, 50)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'lbfgs', 'sgd'],\n",
    "    'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "}\n",
    "\n",
    "parameter_space_trees= {\n",
    "    'n_estimators': [50, 100, 200, 400],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 40, 60, 80, None],\n",
    "    'bootstrap': [False, True],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in ['MLPClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier']:\n",
    "    print(joblib.load(f'{base_dir}/{project_name}/model_selection/{label}_best_params_macro.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "os.makedirs(f'{project_path}/model_selection/', exist_ok=True)\n",
    "\n",
    "scorer = make_scorer(average_precision_score, \n",
    "                     average='macro',\n",
    "                     response_method='predict_proba')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=project.random_seed)\n",
    "\n",
    "for top_base_clf in [RandomForestClassifier(), ExtraTreesClassifier(), MLPClassifier()]:\n",
    "    label= top_base_clf.__class__.__name__\n",
    "    if label == 'MLPClassifier':\n",
    "        parameter_space = parameter_space_MLP\n",
    "    else:\n",
    "        parameter_space = parameter_space_trees\n",
    "    clf = HalvingGridSearchCV(top_base_clf, \n",
    "                          parameter_space, \n",
    "                          n_jobs=-1, \n",
    "                          cv=cv, \n",
    "                          verbose=True, \n",
    "                          random_state=project.random_seed,\n",
    "                          scoring=scorer)\n",
    "    clf.fit(project.X_train, project.y_train)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "\n",
    "    pd.DataFrame(clf.cv_results_).to_csv(f'{project_path}/model_selection/{label}_cv_results_macro.csv', index=False)\n",
    "    joblib.dump(clf.best_params_, f'{project_path}/model_selection/{label}_best_params_macro.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "\n",
    "os.makedirs(f'{project_path}/model_selection/', exist_ok=True)\n",
    "\n",
    "for top_base_clf in [RandomForestClassifier(n_jobs=-1), ExtraTreesClassifier(n_jobs=-1), MLPClassifier()]:    \n",
    "    label = top_base_clf.__class__.__name__\n",
    "    clf = top_base_clf\n",
    "    project.set_clf(clf)\n",
    "    y_test, y_pred, y_proba = project.cv_fit_pred(name=label)\n",
    "    results[label+'_untuned'] = [y_test, y_pred, y_proba]\n",
    "\n",
    "    best_params = joblib.load(f'{project_path}/model_selection/{label}_best_params_macro.joblib')\n",
    "    print(f'Best parameters for {label}: {best_params}')\n",
    "    if label != 'MLPClassifier':\n",
    "        best_params['n_jobs'] = -1\n",
    "    clf = top_base_clf.set_params(**best_params)\n",
    "    project.set_clf(clf)\n",
    "    y_test, y_pred, y_proba = project.cv_fit_pred(name=label+'_tuned')\n",
    "    results[label+'_tuned'] = [y_test, y_pred, y_proba]\n",
    "    joblib.dump(results, f'{project_path}/model_selection/top3models_results.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629621d",
   "metadata": {},
   "source": [
    "2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_loc_dict={}\n",
    "best_params = joblib.load(f'{project_path}/model_selection/RandomForestClassifier_best_params_macro.joblib')\n",
    "clf = RandomForestClassifier(**best_params, n_jobs=-1)\n",
    "project.set_clf(clf)\n",
    "\n",
    "location_order = ['Membrane', 'Cytoplasm', 'Nucleus', 'Cell', 'All']\n",
    "stat_order = ['Min', 'Max', 'Std.Dev.', 'Median', 'Mean', 'All']\n",
    "\n",
    "for location in location_order:\n",
    "    stats_loc_dict[location] = {}\n",
    "    included_cols = [col for col in project.column_names if location in col]\n",
    "    if location == 'All':\n",
    "        included_cols = project.column_names\n",
    "    for stat in stat_order:\n",
    "        if stat == 'All':\n",
    "            selected_cols = included_cols\n",
    "        else:\n",
    "            selected_cols = [col for col in included_cols if stat in col]\n",
    "\n",
    "        y_test, y_pred, y_proba = project.cv_fit_pred(name=f'RF_{location}_{stat}', included_cols=selected_cols)\n",
    "        stats_loc_dict[location][stat] = [y_test, y_pred, y_proba]\n",
    "        joblib.dump(stats_loc_dict, f'{project_path}/model_selection/stats_loc_dict_included.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67f7da",
   "metadata": {},
   "source": [
    "2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "stats_loc_dict={}\n",
    "\n",
    "best_params = joblib.load(f'{project_path}/model_selection/RandomForestClassifier_best_params_macro.joblib')\n",
    "clf = RandomForestClassifier(**best_params, n_jobs=-1)\n",
    "project.set_clf(clf)\n",
    "\n",
    "location_order = ['Membrane', 'Cytoplasm', 'Nucleus', 'Cell', 'All']\n",
    "stat_order = ['Min', 'Max', 'Std.Dev.', 'Median', 'Mean', 'All']\n",
    "\n",
    "for location in location_order:\n",
    "    stats_loc_dict[location] = {}\n",
    "    included_cols = [col for col in project.column_names if location in col]\n",
    "    if location == 'All':\n",
    "        included_cols = project.column_names\n",
    "    for stat in stat_order:\n",
    "        if stat == 'All':\n",
    "            selected_cols = included_cols\n",
    "        else:\n",
    "            selected_cols = [col for col in included_cols if stat in col]\n",
    "\n",
    "        if location == 'All' and stat == 'All':\n",
    "            stats_loc_dict[location][stat] = [None, None, None]\n",
    "        else:\n",
    "            y_test, y_pred, y_proba = project.cv_fit_pred(name=f'RF_{location}_{stat}', excluded_cols=selected_cols)\n",
    "            stats_loc_dict[location][stat] = [y_test, y_pred, y_proba]\n",
    "\n",
    "        joblib.dump(stats_loc_dict, f'{project_path}/model_selection/stats_loc_dict_excluded.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5544fe8",
   "metadata": {},
   "source": [
    "### 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = joblib.load(f'/store/Projects/wboohar/PhenoCycler/QuantCellPaper/model_selection/RandomForestClassifier_best_params_macro.joblib')\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    **best_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=project.random_seed\n",
    ")\n",
    "\n",
    "project.set_clf(classifier)\n",
    "\n",
    "project.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28808a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = project.codex.cell_type.value_counts()\n",
    "fraction_annotated = {}\n",
    "fraction_annotated['Conventional'] = counts[counts.index!='Other'].sum() / counts.sum()\n",
    "FDR_tests = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0]\n",
    "\n",
    "for fdr in FDR_tests:\n",
    "    project.relabel_unannotated(FDR_cutoff=fdr)\n",
    "    relabeled_counts = pd.Series(project.relabeled_labels).value_counts()\n",
    "    fraction_annotated[f'FDR < {int(fdr*100)}%'] = relabeled_counts[relabeled_counts.index!='Other'].sum() / counts.sum()\n",
    "\n",
    "joblib.dump(fraction_annotated, f'{project_path}/fraction_annotated.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf8078",
   "metadata": {},
   "source": [
    "3E and S2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e94e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = project.target_encoder\n",
    "if not os.path.exists(f'{project_path}/label_encoder.joblib'):\n",
    "    joblib.dump(encoder, f'{project_path}/label_encoder.joblib')\n",
    "else:\n",
    "    encoder = joblib.load(f'{project_path}/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codex = codex_project()\n",
    "codex.read_csv(f'{project_path}/codex_conventional_{project_name}.csv', project_name=project_name)\n",
    "codex.read_annotation_strategy(annotations_path)\n",
    "combos=codex._marker_combos\n",
    "\n",
    "codex.codex = codex.codex.loc[codex.codex.loc[:, 'cell_type'] != 'Other', :]\n",
    "codex.codex = codex.codex.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(codex.codex, codex.codex['cell_type'], \n",
    "    test_size=0.2, \n",
    "    random_state=project.random_seed, \n",
    "    stratify=codex.codex['cell_type'])\n",
    "\n",
    "if not os.path.exists(f'{project_path}/ComparisonsTrainTest.joblib'):\n",
    "    joblib.dump((X_train, X_test, y_train, y_test), f'{project_path}/ComparisonsTrainTest.joblib')\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = joblib.load(f'{project_path}/ComparisonsTrainTest.joblib')\n",
    "    # Reset index for model and validation sets\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0a8dd",
   "metadata": {},
   "source": [
    "## AnnoSpat\n",
    "\n",
    "### Marker Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "annospat_combos = pd.DataFrame(columns=combos.keys())\n",
    "for ct in annospat_combos:\n",
    "    n=0\n",
    "    for marker in combos[ct]:\n",
    "        if marker.count('+'):\n",
    "            marker = marker.split('+')[0]\n",
    "        \n",
    "        annospat_combos.loc[n, ct] = marker\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625544fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{project_path}/AnnoSpat', exist_ok=True)\n",
    "annospat_combos.index = range(1, len(annospat_combos) + 1)\n",
    "annospat_combos.to_csv(f'{project_path}/AnnoSpat/marker_combos.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bbc91",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4653aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[x for x in codex.codex if \": Cell: Mean\" in x]\n",
    "annospat_codex = codex.codex.copy()\n",
    "annospat_codex = annospat_codex.loc[:, columns]\n",
    "annospat_codex = annospat_codex.reset_index(drop=True)\n",
    "annospat_codex = annospat_codex.rename(columns=lambda x: x.split(':')[0])\n",
    "annospat_codex.loc[:, 'ROI'] = annospat_codex.index\n",
    "if not os.path.exists(f'{project_path}/AnnoSpat/marker_data.csv'):\n",
    "    annospat_codex.to_csv(f'{project_path}/AnnoSpat/marker_data.csv', index=True)\n",
    "else:\n",
    "    annospat_codex = pd.read_csv(f'{project_path}/AnnoSpat/marker_data.csv', index_col=0)\n",
    "\n",
    "if not os.path.exists(f'{project_path}/AnnoSpat/annospat_true_labels.csv'):\n",
    "    codex.codex.loc[:, 'cell_type'].to_csv(f'{project_path}/AnnoSpat/annospat_true_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53beb21",
   "metadata": {},
   "source": [
    "## Astir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f7705",
   "metadata": {},
   "source": [
    "### Marker Combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc84a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{project_path}/Astir', exist_ok=True)\n",
    "\n",
    "astir_combos = {}\n",
    "astir_combos['cell_types'] = {}\n",
    "for ct in combos:\n",
    "    if ct not in astir_combos['cell_types']:\n",
    "        astir_combos['cell_types'][ct] = []\n",
    "    for marker in combos[ct]:\n",
    "        if marker.count('+'):\n",
    "            marker = marker.split('+')[0]\n",
    "            astir_combos['cell_types'][ct].append(marker)\n",
    "\n",
    "\n",
    "yaml_string = yaml.dump(astir_combos)\n",
    "\n",
    "with open(f'{project_path}/Astir/marker_combos.yaml', 'w') as f:\n",
    "    f.write(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adc79b",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= [x for x in codex.codex if \": Cell: Mean\" in x]\n",
    "astir_codex = codex.codex.copy()\n",
    "astir_codex.loc[:, 'index'] = astir_codex.index\n",
    "astir_codex = astir_codex.loc[:, ['index'] + columns]\n",
    "astir_codex.columns = astir_codex.columns.str.split(':').str[0]\n",
    "if not os.path.exists(f'{project_path}/Astir/astir_true_labels.csv'):\n",
    "    codex.codex.loc[:, 'cell_type'].to_csv(f'{project_path}/Astir/astir_true_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0904e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{project_path}/Astir/marker_data.csv'):\n",
    "    astir_codex.to_csv(f'{project_path}/Astir/marker_data.csv', index=True)\n",
    "else:\n",
    "    astir_codex = pd.read_csv(f'{project_path}/Astir/marker_data.csv', index_col=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd7af8",
   "metadata": {},
   "source": [
    "## MAPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mask = [project._regex_marker_cols(x) for x in X_train.columns]\n",
    "columns = list(X_train.columns[column_mask])\n",
    "columns = [x for x in columns if 'Cell: Mean' in x]\n",
    "\n",
    "columns.append('Cell: Area µm^2')\n",
    "columns.append('cell_type')\n",
    "\n",
    "maps_codex = X_train.copy()\n",
    "maps_codex = maps_codex.loc[:, columns]\n",
    "maps_codex = maps_codex.reset_index(drop=True)\n",
    "maps_codex = maps_codex.rename(columns=lambda x: x.split(':')[0])\n",
    "\n",
    "maps_codex.rename(columns={'Cell: Area µm^2': 'cellSize', 'cell_type' : 'cell_label'}, inplace=True)\n",
    "\n",
    "os.makedirs(f'{project_path}/MAPS/data/cell_phenotyping/', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_codex.loc[:, 'cell_label'] = encoder.transform(maps_codex.loc[:, 'cell_label'])\n",
    "\n",
    "X = maps_codex.drop(columns=['cell_label'])\n",
    "y = maps_codex['cell_label']\n",
    "\n",
    "maps_test = X_test.loc[:, columns]\n",
    "maps_test.rename(columns={'Cell: Area µm^2': 'cellSize', 'cell_type' : 'cell_label'}, inplace=True)\n",
    "maps_test.loc[:, 'cell_label'] = encoder.transform(maps_test.loc[:, 'cell_label'])\n",
    "\n",
    "maps_X_train, maps_X_valid, maps_y_train, maps_y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "maps_train = pd.concat([maps_X_train.reset_index(drop=True), maps_y_train.reset_index(drop=True)], axis=1)\n",
    "maps_train.to_csv(f'{project_path}/MAPS/data/cell_phenotyping/train_features.csv', index=False)\n",
    "\n",
    "maps_valid = pd.concat([maps_X_valid.reset_index(drop=True), maps_y_valid.reset_index(drop=True)], axis=1)  \n",
    "maps_valid.to_csv(f'{project_path}/MAPS/data/cell_phenotyping/valid_features.csv', index=False)\n",
    "\n",
    "maps_test.to_csv(f'{project_path}/MAPS/data/cell_phenotyping/test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7980ba5",
   "metadata": {},
   "source": [
    "## QuantCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantcell import quantcell_project\n",
    "\n",
    "project = quantcell_project()\n",
    "project.initialize(base_path=base_dir, project_name=project_name)\n",
    "X_valid_wiped = X_valid.copy()\n",
    "X_valid_wiped.loc[:, 'cell_type'] = 'Other'\n",
    "project.codex = pd.concat([X_model, X_valid_wiped], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc449e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ef791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import time\n",
    "best_params = joblib.load(f'{project_path}/model_selection/RandomForestClassifier_best_params_macro.joblib')\n",
    "\n",
    "true_labels = X_valid.loc[:, 'cell_type']\n",
    "true_labels.to_csv(f'{project_path}/quantcell_true_labels.csv', index=True)\n",
    "\n",
    "classifier = RandomForestClassifier(**best_params, n_jobs=-1, random_state=10)\n",
    "\n",
    "project.set_clf(classifier)\n",
    "\n",
    "start = time.time()\n",
    "project.fit()\n",
    "end_fit = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "project.relabel_unannotated(FDR_cutoff=0.05)\n",
    "end_time = time.time()\n",
    "quantcell_labels = pd.Series(project.relabeled_labels)\n",
    "quantcell_labels.to_csv(f'{project_path}/quantcell_labels.csv', index=False)    \n",
    "elapsed_time = end_fit - start + end_time - start_time\n",
    "pd.Series(elapsed_time).to_csv(f'{project_path}/time_elapsed_quantcell.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332ccfe",
   "metadata": {},
   "source": [
    "4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "gene_ko_dict={}\n",
    "\n",
    "best_params = joblib.load(f'{project_path}/model_selection/RandomForestClassifier_best_params_macro.joblib')\n",
    "clf = RandomForestClassifier(**best_params, n_jobs=-1)\n",
    "project.set_clf(clf)\n",
    "\n",
    "gene_order = [x for x in project.column_names if ': Cell: Mean' in x] # every marker has a 'Cell: Mean' column\n",
    "gene_order = [x.split(': Cell: Mean')[0] for x in gene_order]\n",
    "gene_order = sorted(gene_order, key=str.lower)\n",
    "\n",
    "for marker in gene_order:\n",
    "    selected_cols = [col for col in project.column_names if marker in col]\n",
    "    if len(selected_cols) == 0:\n",
    "        raise ValueError(f'No columns found for marker {marker}. Check the column names in the project.')\n",
    "    y_test, y_pred, y_proba = project.cv_fit_pred(name=f'RF_{marker}', excluded_cols=selected_cols)\n",
    "    gene_ko_dict[marker] = [y_test, y_pred, y_proba]\n",
    "    joblib.dump(gene_ko_dict, f'{project_path}/model_selection/gene_ko_dict.joblib')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulab-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
